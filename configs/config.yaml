# Project Configuration
project:
  name: "books-classification"
  version: "1.0.0"
  description: "Multi-label classification of English book sentences using semantic embeddings"

# Data Configuration (Step 1)
data:
  corpus_name: "IsmaelMousa/books"
  selected_books:
    - "Anna Karenina"
    - "The Adventures of Alice in Wonderland"
    - "Frankenstein"
    - "Wuthering Heights"
  max_sentences_per_book: null  # Use all sentences
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15
  max_sentence_length: 512
  min_sentence_length: 10
  random_seed: 42
  
  # Data preprocessing
  preprocessing:
    remove_duplicates: true
    normalize_text: true
    remove_special_chars: false
    lowercase: false

# Semantic Model Selection (Step 2)
semantic_models:
  candidates:
    - "sentence-transformers/all-MiniLM-L6-v2"
    - "sentence-transformers/all-mpnet-base-v2"
    - "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    - "sentence-transformers/paraphrase-MiniLM-L3-v2"
  
  # Selected best model from Step 2
  selected_model: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
  
  evaluation:
    similarity_threshold: 0.7
    test_pairs_file: "data/generated_similarity_pairs.json"
    metrics: ["cosine_similarity", "semantic_similarity_score"]

# Model Configuration (Step 3)
model:
  encoder:
    model_name: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    hidden_size: 384
    max_length: 512
  
  semantic_embedding:
    contrastive_learning:
      temperature: 0.1
      margin: 0.3
      negative_sampling_ratio: 3

# Evaluation (Step 6)
evaluation:
  metrics:
    classification: ["precision", "recall", "f1", "hamming_loss"]
    semantic: ["cosine_similarity", "semantic_similarity"]
    performance: ["training_time", "inference_time", "model_size"]
  
  visualization:
    comparison_charts: true
    per_category_analysis: true
    confusion_matrices: true

# Training Configuration
training:
  batch_size: 32
  gradient_accumulation_steps: 2
  max_grad_norm: 1.0
  warmup_steps: 500
  weight_decay: 0.01
  early_stopping_patience: 5
  save_best_model: true
  checkpoint_dir: "experiments/checkpoints"
  log_dir: "experiments/logs"

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "experiments/logs/project.log"

# Hardware Configuration
hardware:
  device: "auto"  # "cpu", "cuda", "mps", or "auto"
  num_workers: 4
  pin_memory: true
  mixed_precision: true 