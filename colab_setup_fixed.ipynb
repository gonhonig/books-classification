{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "setup_header"
      },
      "source": [
       "# ğŸ“š Books Classification - Fixed Cloud GPU Training\n",
       "\n",
       "This notebook trains a book sentence classification model using GPU acceleration on Google Colab.\n",
       "\n",
       "**Fixed Issues:**\n",
       "- CUDA version mismatches\n",
       "- Datasets protocol compatibility\n",
       "- Package version conflicts\n",
       "\n",
       "**Selected Books:**\n",
       "- Anna Karenina (Classics)\n",
       "- The Adventures of Alice in Wonderland (Children's Books)\n",
       "- Frankenstein (Science-Fiction)\n",
       "- The Life of Julius Caesar (Biographies)\n",
       "\n",
       "**Model:** Constructive Learning Model with BERT encoder"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "gpu_check"
      },
      "source": [
       "## ğŸ” GPU Check\n",
       "\n",
       "First, let's verify we have GPU access:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "id": "gpu_verification"
      },
      "outputs": [],
      "source": [
       "import torch\n",
       "print(f\"PyTorch version: {torch.__version__}\")\n",
       "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
       "if torch.cuda.is_available():\n",
       "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
       "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
       "    print(f\"GPU Memory Available: {torch.cuda.memory_allocated(0) / 1e9:.1f} GB used\")\n",
       "else:\n",
       "    print(\"âš ï¸  No GPU detected! Please enable GPU in Runtime > Change runtime type\")\n",
       "    print(\"   Runtime > Change runtime type > Hardware accelerator: GPU\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "fix_versions"
      },
      "source": [
       "## ğŸ”§ Fix Package Versions\n",
       "\n",
       "This cell fixes CUDA version mismatches and datasets protocol issues:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "id": "fix_package_versions"
      },
      "outputs": [],
      "source": [
       "# Uninstall problematic packages\n",
       "!pip uninstall -y torch torchvision torchaudio datasets transformers\n",
       "\n",
       "# Install compatible PyTorch with CUDA 11.8\n",
       "!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n",
       "\n",
       "# Install compatible datasets and transformers\n",
       "!pip install datasets==2.14.0 transformers==4.30.2 tokenizers==0.13.3\n",
       "\n",
       "# Install other dependencies\n",
       "!pip install accelerate==0.20.3 deepspeed==0.9.5\n",
       "!pip install nltk scikit-learn pandas numpy matplotlib seaborn\n",
       "!pip install wandb tensorboard tqdm PyYAML\n",
       "\n",
       "# Verify installation\n",
       "import torch\n",
       "import datasets\n",
       "import transformers\n",
       "print(f\"âœ… PyTorch {torch.__version__} installed successfully\")\n",
       "print(f\"âœ… Datasets {datasets.__version__} installed successfully\")\n",
       "print(f\"âœ… Transformers {transformers.__version__} installed successfully\")\n",
       "print(f\"âœ… CUDA available: {torch.cuda.is_available()}\")\n",
       "if torch.cuda.is_available():\n",
       "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "download_nltk"
      },
      "source": [
       "## ğŸ“¥ Download NLTK Data\n",
       "\n",
       "Download required NLTK data for sentence tokenization:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "id": "nltk_download"
      },
      "outputs": [],
      "source": [
       "import nltk\n",
       "nltk.download('punkt')\n",
       "nltk.download('punkt_tab')\n",
       "print(\"âœ… NLTK data downloaded successfully!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "upload_files"
      },
      "source": [
       "## ğŸ“¤ Upload Project Files\n",
       "\n",
       "Upload your project files to Colab:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "id": "file_upload_zip"
      },
      "outputs": [],
      "source": [
       "from google.colab import files\n",
       "import zipfile\n",
       "import os\n",
       "\n",
       "print(\"ğŸ“¤ Please upload the books_classification_colab.zip file:\")\n",
       "uploaded = files.upload()\n",
       "\n",
       "# Extract the uploaded file\n",
       "for filename in uploaded.keys():\n",
       "    if filename.endswith('.zip'):\n",
       "        print(f\"ğŸ“¦ Extracting {filename}...\")\n",
       "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
       "            zip_ref.extractall('.')\n",
       "        print(f\"âœ… Extracted {filename}\")\n",
       "        break\n",
       "    else:\n",
       "        print(f\"âš ï¸  {filename} is not a ZIP file. Please upload books_classification_colab.zip\")\n",
       "\n",
       "print(\"ğŸ“ Files uploaded and extracted!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "verify_files"
      },
      "source": [
       "## âœ… Verify Project Files\n",
       "\n",
       "Let's verify that all necessary files are present:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "id": "check_files"
      },
      "outputs": [],
      "source": [
       "import os\n",
       "\n",
       "required_files = [\n",
       "    'configs/config.yaml',\n",
       "    'data/prepare_data.py',\n",
       "    'models/constructive_model.py',\n",
       "    'train_cloud.py',\n",
       "    'requirements-cloud.txt'\n",
       "]\n",
       "\n",
       "print(\"ğŸ” Checking required files:\")\n",
       "all_present = True\n",
       "for file_path in required_files:\n",
       "    if os.path.exists(file_path):\n",
       "        print(f\"âœ… {file_path}\")\n",
       "    else:\n",
       "        print(f\"âŒ {file_path} - MISSING\")\n",
       "        all_present = False\n",
       "\n",
       "if all_present:\n",
       "    print(\"\\nğŸ‰ All files present! Ready to proceed.\")\n",
       "else:\n",
       "    print(\"\\nâš ï¸  Some files are missing. Please check the upload.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "prepare_data"
      },
      "source": [
       "## ğŸ—‚ï¸ Prepare Data\n",
       "\n",
       "Run data preparation to download and process the books dataset:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "id": "run_data_prep"
      },
      "outputs": [],
      "source": [
       "import sys\n",
       "sys.path.append('.')\n",
       "\n",
       "print(\"ğŸ“š Starting data preparation...\")\n",
       "!python data/prepare_data.py\n",
       "print(\"âœ… Data preparation completed!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "verify_dataset"
      },
      "source": [
       "## ğŸ“Š Verify Dataset\n",
       "\n",
       "Let's check the prepared dataset with the fixed datasets version:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "id": "check_dataset"
      },
      "outputs": [],
      "source": [
       "from datasets import load_from_disk\n",
       "import json\n",
       "\n",
       "# Load dataset with fixed datasets version\n",
       "try:\n",
       "    dataset = load_from_disk('data/processed_dataset')\n",
       "    print(f\"ğŸ“Š Dataset loaded successfully!\")\n",
       "    print(f\"   Train: {len(dataset['train'])} samples\")\n",
       "    print(f\"   Validation: {len(dataset['validation'])} samples\")\n",
       "    print(f\"   Test: {len(dataset['test'])} samples\")\n",
       "    \n",
       "    # Load metadata\n",
       "    with open('data/metadata.json', 'r') as f:\n",
       "        metadata = json.load(f)\n",
       "    \n",
       "    print(f\"\\nğŸ“š Books in dataset:\")\n",
       "    for book_id, book_name in metadata['id_to_label'].items():\n",
       "        print(f\"   {book_id}: {book_name}\")\n",
       "    \n",
       "    # Show sample\n",
       "    print(f\"\\nğŸ“ Sample sentence:\")\n",
       "    print(f\"   {dataset['train'][0]['sentence'][:100]}...\")\n",
       "    \n",
       "except Exception as e:\n",
       "    print(f\"âŒ Error loading dataset: {e}\")\n",
       "    print(\"This might be due to datasets version incompatibility.\")\n",
       "    print(\"Please restart the runtime and run the fix cell again.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "setup_wandb"
      },
      "source": [
       "## ğŸ“Š Setup Weights & Biases (Optional)\n",
       "\n",
       "Setup experiment tracking for monitoring training progress:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "id": "wandb_login"
      },
      "outputs": [],
      "source": [
       "import wandb\n",
       "\n",
       "# Uncomment the line below to login to WandB\n",
       "# wandb.login()\n",
       "\n",
       "print(\"ğŸ“Š WandB setup completed!\")\n",
       "print(\"ğŸ’¡ To enable experiment tracking, uncomment 'wandb.login()' above\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "start_training"
      },
      "source": [
       "## ğŸš€ Start Training\n",
       "\n",
       "Start the cloud-optimized training with GPU acceleration:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "id": "run_training"
      },
      "outputs": [],
      "source": [
       "print(\"ğŸš€ Starting GPU training...\")\n",
       "print(f\"ğŸ¯ Training on: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
       "\n",
       "# Start training with 5 epochs for quick testing\n",
       "!python train_cloud.py --epochs 5\n",
       "\n",
       "print(\"âœ… Training completed!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "check_results"
      },
      "source": [
       "## ğŸ“ˆ Check Training Results\n",
       "\n",
       "Let's check the training results and model performance:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "id": "view_results"
      },
      "outputs": [],
      "source": [
       "import os\n",
       "import glob\n",
       "\n",
       "print(\"ğŸ“Š Training Results:\")\n",
       "\n",
       "# Check for checkpoints\n",
       "checkpoints = glob.glob('experiments/checkpoints/*.pt')\n",
       "if checkpoints:\n",
       "    print(f\"âœ… Found {len(checkpoints)} checkpoints:\")\n",
       "    for checkpoint in sorted(checkpoints):\n",
       "        size_mb = os.path.getsize(checkpoint) / 1024 / 1024\n",
       "        print(f\"   ğŸ“ {os.path.basename(checkpoint)} ({size_mb:.1f} MB)\")\n",
       "else:\n",
       "    print(\"âš ï¸  No checkpoints found\")\n",
       "\n",
       "# Check for logs\n",
       "logs = glob.glob('experiments/logs/*.log')\n",
       "if logs:\n",
       "    print(f\"\\nğŸ“ Found {len(logs)} log files:\")\n",
       "    for log in logs:\n",
       "        print(f\"   ğŸ“„ {os.path.basename(log)}\")\n",
       "\n",
       "print(\"\\nğŸ‰ Training results ready!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "test_model"
      },
      "source": [
       "## ğŸ§ª Test Model\n",
       "\n",
       "Test the trained model with sample sentences:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "id": "model_test"
      },
      "outputs": [],
      "source": [
       "print(\"ğŸ§ª Testing trained model...\")\n",
       "!python test_prediction.py\n",
       "print(\"âœ… Model testing completed!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "download_results"
      },
      "source": [
       "## ğŸ“¥ Download Results\n",
       "\n",
       "Download the training results and model files:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "id": "download_files"
      },
      "outputs": [],
      "source": [
       "import zipfile\n",
       "import os\n",
       "\n",
       "print(\"ğŸ“¦ Creating results package...\")\n",
       "\n",
       "# Create a zip file with results\n",
       "with zipfile.ZipFile('training_results.zip', 'w') as zipf:\n",
       "    # Add experiments directory\n",
       "    if os.path.exists('experiments'):\n",
       "        for root, dirs, files in os.walk('experiments'):\n",
       "            for file in files:\n",
       "                file_path = os.path.join(root, file)\n",
       "                zipf.write(file_path, file_path)\n",
       "    \n",
       "    # Add data directory\n",
       "    if os.path.exists('data'):\n",
       "        for root, dirs, files in os.walk('data'):\n",
       "            for file in files:\n",
       "                file_path = os.path.join(root, file)\n",
       "                zipf.write(file_path, file_path)\n",
       "\n",
       "# Download the results\n",
       "files.download('training_results.zip')\n",
       "print(\"âœ… Results downloaded to your computer!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "id": "next_steps"
      },
      "source": [
       "## ğŸ¯ Next Steps\n",
       "\n",
       "### What you can do next:\n",
       "\n",
       "1. **ğŸ“Š Analyze Results**: Check the training logs and metrics\n",
       "2. **ğŸ”§ Fine-tune**: Adjust hyperparameters in `configs/config.yaml`\n",
       "3. **ğŸš€ Scale Up**: Train for more epochs or use larger models\n",
       "4. **ğŸ“± Deploy**: Use the trained model for inference\n",
       "5. **ğŸ“ˆ Monitor**: Set up WandB for better experiment tracking\n",
       "\n",
       "### Performance Tips:\n",
       "\n",
       "- **Free Colab**: Limited to ~12 hours, use for testing\n",
       "- **Colab Pro**: More hours, better GPUs (V100/A100)\n",
       "- **Batch Size**: Adjust based on GPU memory\n",
       "- **Checkpointing**: Saves progress every epoch\n",
       "\n",
       "### ğŸ‰ Congratulations!\n",
       "\n",
       "You've successfully trained a book sentence classification model on Google Colab with GPU acceleration!"
      ]
     }
    ],
    "metadata": {
     "accelerator": "GPU",
     "colab": {
      "gpuType": "T4",
      "provenance": []
     },
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_edit": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   } 